{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMY3q9TkwsIK+rWVSOQ0MSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohgawditsal/SWMTWA/blob/main/Seeing_with_Machines%2C_Thinking_with_Archives_Computational_Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seeing with Machines, Thinking with Archives: Computational Workflow"
      ],
      "metadata": {
        "id": "ATmsAh-Ho9Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Thesis & Workflow Description"
      ],
      "metadata": {
        "id": "uRPzoP-lpFXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script provides a complete Python pipeline for analyzing the color characteristics of a historical film, designed to be run in Google Colab.\n",
        "It follows the methodology outlined in the thesis:\n",
        "1. Setup: Installs necessary libraries and prepares the environment.\n",
        "2. Frame Extraction: Uses FFmpeg to extract frames from a video file.\n",
        "3. Colro Analysis: For each frame, it calculates:\n",
        "  - The 'k' dominant colors using k-means clustering.\n",
        "  - The average Hue, Saturation, and Value (HSV)\n",
        "4. Data Aggregation: Stores the extracted color data in a Pandas DataFrame.\n",
        "5. Visualization: Generates several plots to visualize the film's color:\n",
        "  - A temporal \"color barcode\" of the entire film.\n",
        "  - An overall color palette for the film.\n",
        "  - Line graphs of average, Hue, Stauration, and Value over time.\n",
        "  - A histogram of hue distribution for the entire film."
      ],
      "metadata": {
        "id": "yDkLOZsKpIva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to use on Google Colab:\n",
        "1. Upload the video file to your Google Drive.\n",
        "2. Run the first cell (Step 1) to install libraries and mount your Google Drive.\n",
        "3. In the second cell (Step 2), update the 'video_path' variable to point to your video file in Google Drive.\n",
        "4. Adjust parameters like 'K_CLUSTERS' and 'FPS_TO_EXTRACT' as needed.\n",
        "5. Run remaining cells sequentially. The script will create output folders in your specifices 'output_base_path' for frames, data (CSV), and plots."
      ],
      "metadata": {
        "id": "wDBS85v3qu9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1: SETUP AND IMPORTS\n"
      ],
      "metadata": {
        "id": "1HPPcm5srQZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install necessary libraries.\n",
        "tqdm is used for progress bars."
      ],
      "metadata": {
        "id": "Jk_6E4CurVt7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCdWjZyjou2W",
        "outputId": "d34d2f9b-9691-486b-eb70-3395c8e49967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 43, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dependencies)\n",
            "                                       ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 175, in version\n",
            "    return parse_version(self._dist.version)\n",
            "                         ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 632, in version\n",
            "    return self.metadata['Version']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 56, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 466, in _parsegen\n",
            "    lines.append(line)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1526, in critical\n",
            "    def critical(self, msg, *args, **kwargs):\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "\n",
        "# mount google drive to access files\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    print(\"Please ensure you are running this in a Google Colab environment.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1.1: DOWNLOADING FROM A PUBLIC SOURCE"
      ],
      "metadata": {
        "id": "MOUzXdCCyekW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install yt-dlp, a tool for downloading videos from YouTube and other sites.\n",
        "!pip install yt-dlp\n",
        "\n",
        "# URL of a legitimately free-to-view archival film (e.g., from BFI's YouTube channel)\n",
        "# here we have the URL of \"The Cabinet of Dr. Caligary (1920)\"\n",
        "video_url = 'https://www.youtube.com/watch?v=nQSzEe3xqf4'\n",
        "\n",
        "# define where to save the downloaded video\n",
        "download_folder = '/content/drive/MyDrive/MASTERSTHESIS/VIDEOS'\n",
        "os.makedirs(download_folder, exist_ok=True)\n",
        "downloaded_video_path = os.path.join(download_folder, 'royaljourney_1951.mp4')\n",
        "\n",
        "# use yt-dlp to download the video in mp4 format\n",
        "!yt-dlp -o \"{downloaded_video_path}\" -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best' \"{video_url}\"\n",
        "\n",
        "# NOW, you can set your VIDEO_PATH to this downloaded file\n",
        "# VIDEO_PATH = downloaded_video_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZdAUvhbyVMj",
        "outputId": "21fd0de0-1fa7-493f-8d44-39e4ee150034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.6.9)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=nQSzEe3xqf4\n",
            "[youtube] nQSzEe3xqf4: Downloading webpage\n",
            "[youtube] nQSzEe3xqf4: Downloading tv client config\n",
            "[youtube] nQSzEe3xqf4: Downloading tv player API JSON\n",
            "[youtube] nQSzEe3xqf4: Downloading ios player API JSON\n",
            "[youtube] nQSzEe3xqf4: Downloading m3u8 information\n",
            "[info] nQSzEe3xqf4: Downloading 1 format(s): 137+140\n",
            "[download] Destination: /content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.f137.mp4\n",
            "\u001b[K[download] 100% of    1.16GiB in \u001b[1;37m00:07:44\u001b[0m at \u001b[0;32m2.55MiB/s\u001b[0m\n",
            "[download] Destination: /content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.f140.m4a\n",
            "\u001b[K[download] 100% of   47.85MiB in \u001b[1;37m00:00:13\u001b[0m at \u001b[0;32m3.55MiB/s\u001b[0m\n",
            "[Merger] Merging formats into \"/content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.mp4\"\n",
            "Deleting original file /content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.f140.m4a (pass -k to keep)\n",
            "Deleting original file /content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.f137.mp4 (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2: CONFIGURATION AND PARAMETERS"
      ],
      "metadata": {
        "id": "e4nY1yxVv0QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: CHANGE THIS to the path of your video file in Google Drive.\n",
        "VIDEO_PATH = '/content/drive/MyDrive/MASTERSTHESIS/VIDEOS/royaljourney_1951.mp4'\n",
        "\n",
        "# TODO: CHANGE THIS to a base path in your Google Drive where all output will be saved.\n",
        "# the script will create subfolders within this path.\n",
        "OUTPUT_BASE_PATH = '/content/drive/MyDrive/MASTERSTHESIS/OUTPUT'\n",
        "\n",
        "# name for this specific film's analysis (used to create a unique output folder).\n",
        "FILM_NAME = 'royaljourney_1951'\n",
        "\n",
        "# number of dominant colors to extract from each frame.\n",
        "K_CLUSTERS = 5\n",
        "\n",
        "# number of frames to extract per second from the video.\n",
        "# 1 is a good default for general analysis.\n",
        "FPS_TO_EXTRACT = 1\n",
        "\n",
        "# width to resize frames to for faster processing. Aspect ratio is maintained.\n",
        "RESIZE_WIDTH = 640"
      ],
      "metadata": {
        "id": "67ybWRkOv4jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AUTOMATIC PATH CONFIGURATION\n",
        "# create a main directory for this film's analysis.\n",
        "FILM_OUTPUT_PATH = os.path.join(OUTPUT_BASE_PATH, FILM_NAME)\n",
        "FRAMES_FOLDER = os.path.join(FILM_OUTPUT_PATH, 'frames')\n",
        "PLOTS_FOLDER = os.path.join(FILM_OUTPUT_PATH, 'plots')\n",
        "DATA_FOLDER = os.path.join(FILM_OUTPUT_PATH, 'data')\n",
        "\n",
        "# create the necessary directories if they don't exist.\n",
        "os.makedirs(FRAMES_FOLDER, exist_ok=True)\n",
        "os.makedirs(PLOTS_FOLDER, exist_ok=True)\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "\n",
        "print(f\"Configuration complete. Output will be saved to: {FILM_OUTPUT_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enu5ltVJwFK0",
        "outputId": "1d51a6de-5911-4caa-ca1a-ff6ae7bf935b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration complete. Output will be saved to: /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: HELPER FUNCTIONS"
      ],
      "metadata": {
        "id": "PoFlnsC5wID_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_path, output_folder, fps):\n",
        "    \"\"\"\n",
        "    extracts frames from a video file using FFmpeg.\n",
        "    args:\n",
        "        video_path (str): path to the video file.\n",
        "        output_folder (str): directory to save the extracted frames.\n",
        "        fps (int): number of frames to extract per second.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Starting Frame Extraction (at {fps} FPS) ---\")\n",
        "\n",
        "    # clean up old frames if they exist\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "    command = [\n",
        "        'ffmpeg',\n",
        "        '-i', video_path,\n",
        "        '-vf', f'fps={fps}',\n",
        "        '-q:v', '2',  # high quality JPEGs\n",
        "        os.path.join(output_folder, 'frame_%05d.jpg')\n",
        "    ]\n",
        "    try:\n",
        "        # Using subprocess.run to execute the command\n",
        "        process = subprocess.run(command, check=True, capture_output=True, text=True)\n",
        "        print(\"Frames extracted successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"ERROR: FFmpeg not found. This script requires FFmpeg to be installed.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"ERROR during frame extraction: {e}\")\n",
        "        print(f\"FFmpeg stderr: {e.stderr}\")\n",
        "\n",
        "def rgb_to_hex(rgb_color):\n",
        "    \"\"\"converts an RGB color tuple to a hex string.\"\"\"\n",
        "    return mcolors.to_hex(np.array(rgb_color) / 255.0)\n",
        "\n",
        "def analyze_frame_colors(frame_path, k, resize_width):\n",
        "    \"\"\"\n",
        "    analyzes a single image frame to extract dominant colors and average HSV.\n",
        "    args:\n",
        "        frame_path (str): path to the image file.\n",
        "        k (int): number of dominant colors to find.\n",
        "        resize_width (int): width to resize the image to.\n",
        "    returns:\n",
        "        dict: a dictionary containing analysis results, or None if error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # load the image with OpenCV\n",
        "        img = cv2.imread(frame_path)\n",
        "        if img is None:\n",
        "            return None\n",
        "\n",
        "        # resize the image to speed up processing\n",
        "        aspect_ratio = img.shape[0] / img.shape[1]\n",
        "        new_height = int(resize_width * aspect_ratio)\n",
        "        resized_img = cv2.resize(img, (resize_width, new_height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # convert from BGR (OpenCV default) to RGB for analysis and display\n",
        "        img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # convert to HSV for calculating average values\n",
        "        img_hsv = cv2.cvtColor(resized_img, cv2.COLOR_BGR2HSV)\n",
        "        avg_h = np.mean(img_hsv[:, :, 0])\n",
        "        avg_s = np.mean(img_hsv[:, :, 1])\n",
        "        avg_v = np.mean(img_hsv[:, :, 2])\n",
        "\n",
        "        # reshape the image to be a list of pixels for k-means\n",
        "        pixels = img_rgb.reshape((-1, 3))\n",
        "        pixels = np.float32(pixels)\n",
        "\n",
        "        # perform k-means clustering\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
        "        kmeans.fit(pixels)\n",
        "\n",
        "        # get the cluster centers (dominant colors) and their proportions\n",
        "        dominant_colors_rgb = kmeans.cluster_centers_.astype(int)\n",
        "        labels, counts = np.unique(kmeans.labels_, return_counts=True)\n",
        "        proportions = counts / len(pixels)\n",
        "\n",
        "        # sort colors by proportion (most dominant first)\n",
        "        sorted_indices = np.argsort(proportions)[::-1]\n",
        "        dominant_colors_rgb = dominant_colors_rgb[sorted_indices]\n",
        "        proportions = proportions[sorted_indices]\n",
        "\n",
        "        # convert dominant colors to hex codes\n",
        "        dominant_colors_hex = [rgb_to_hex(color) for color in dominant_colors_rgb]\n",
        "\n",
        "        return {\n",
        "            'dominant_colors_hex': dominant_colors_hex,\n",
        "            'dominant_colors_rgb': [tuple(c) for c in dominant_colors_rgb],\n",
        "            'proportions': proportions.tolist(),\n",
        "            'avg_hue': avg_h,\n",
        "            'avg_saturation': avg_s,\n",
        "            'avg_value': avg_v\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process frame {frame_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "4y-LBHp7wMOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4: VISUALIZATION FUNCTIONS"
      ],
      "metadata": {
        "id": "6N2kUi2Jwg6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_color_barcode(df, output_path, title):\n",
        "    \"\"\"generates and saves a color barcode visualization for the film.\"\"\"\n",
        "    print(\"\\n--- Generating Color Barcode ---\")\n",
        "    num_frames = len(df)\n",
        "    barcode = np.zeros((max(100, num_frames // 10), num_frames, 3), dtype=np.uint8)\n",
        "\n",
        "    # get the most dominant color for each frame\n",
        "    dominant_colors = [colors[0] for colors in df['dominant_colors_rgb']]\n",
        "\n",
        "    for i, color in enumerate(dominant_colors):\n",
        "        barcode[:, i, :] = color\n",
        "\n",
        "    plt.figure(figsize=(20, 3))\n",
        "    plt.imshow(barcode, aspect='auto')\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel(\"Time (Frame Number / Extracted FPS)\")\n",
        "    plt.yticks([])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Color barcode saved to {output_path}\")\n",
        "\n",
        "def plot_temporal_graphs(df, output_path_base, title):\n",
        "    \"\"\"generates and saves plots of average HSV over time.\"\"\"\n",
        "    print(\"\\n--- Generating Temporal HSV Plots ---\")\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
        "    fig.suptitle(f'Color Properties Over Time: {title}', fontsize=16)\n",
        "\n",
        "    # hue plot\n",
        "    ax1.plot(df.index, df['avg_hue'], color='r', alpha=0.7)\n",
        "    ax1.set_title('Average Hue')\n",
        "    ax1.set_ylabel('Hue (0-179)')\n",
        "    ax1.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # saturation plot\n",
        "    ax2.plot(df.index, df['avg_saturation'], color='g', alpha=0.7)\n",
        "    ax2.set_title('Average Saturation')\n",
        "    ax2.set_ylabel('Saturation (0-255)')\n",
        "    ax2.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    # value (brightness) plot\n",
        "    ax3.plot(df.index, df['avg_value'], color='b', alpha=0.7)\n",
        "    ax3.set_title('Average Value (Brightness)')\n",
        "    ax3.set_ylabel('Value (0-255)')\n",
        "    ax3.set_xlabel('Time (Frame Number / Extracted FPS)')\n",
        "    ax3.grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    output_path = f\"{output_path_base}_hsv_temporal.png\"\n",
        "    plt.savefig(output_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Temporal graphs saved to {output_path}\")\n",
        "\n",
        "def plot_overall_palette(df, output_path, title, top_n=10):\n",
        "    \"\"\"Generates and saves a summary color palette for the entire film.\"\"\"\n",
        "    print(\"\\n--- Generating Overall Film Palette ---\")\n",
        "    all_colors = []\n",
        "    all_proportions = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        all_colors.extend(row['dominant_colors_rgb'])\n",
        "        all_proportions.extend(row['proportions'])\n",
        "\n",
        "    # create a DataFrame of all dominant colors and their frame proportions\n",
        "    palette_df = pd.DataFrame({\n",
        "        'color_rgb': [tuple(c) for c in all_colors],\n",
        "        'proportion': all_proportions\n",
        "    })\n",
        "\n",
        "    # group by color and sum the proportions to get overall dominance\n",
        "    overall_palette = palette_df.groupby('color_rgb')['proportion'].sum().sort_values(ascending=False)\n",
        "    overall_palette = (overall_palette / df.shape[0]) # normalize by number of frames\n",
        "\n",
        "    top_colors = overall_palette.head(top_n)\n",
        "\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    plt.pie(top_colors, labels=[str(c) for c in top_colors.index],\n",
        "            colors=[np.array(c)/255.0 for c in top_colors.index],\n",
        "            autopct='%1.1f%%', startangle=90)\n",
        "    plt.title(f'Overall Color Palette (Top {top_n} Dominant Hues): {title}', fontsize=14)\n",
        "    plt.axis('equal') # equal aspect ratio ensures that pie is drawn as a circle.\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Overall palette saved to {output_path}\")\n",
        "\n",
        "def plot_hue_histogram(df, output_path, title):\n",
        "    \"\"\"generates and saves a histogram of hue distribution for the entire film.\"\"\"\n",
        "    print(\"\\n--- Generating Hue Distribution Histogram ---\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.hist(df['avg_hue'], bins=45, range=(0, 180), color='cyan', edgecolor='black')\n",
        "    plt.title(f'Overall Hue Distribution: {title}', fontsize=16)\n",
        "    plt.xlabel('Hue Value (0-179, from HSV)')\n",
        "    plt.ylabel('Number of Frames')\n",
        "    plt.grid(axis='y', alpha=0.75, linestyle='--')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300)\n",
        "    plt.close()\n",
        "    print(f\"Hue histogram saved to {output_path}\")"
      ],
      "metadata": {
        "id": "tacfyFquwjsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5: MAIN EXECUTION SCRIPT"
      ],
      "metadata": {
        "id": "9AQ5XaFbw3Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # --- 1. extract frames ---\n",
        "    extract_frames(VIDEO_PATH, FRAMES_FOLDER, FPS_TO_EXTRACT)\n",
        "\n",
        "    # --- 2. analyze frames ---\n",
        "    print(\"\\n--- Analyzing Frames for Color Data ---\")\n",
        "    frame_files = sorted([os.path.join(FRAMES_FOLDER, f) for f in os.listdir(FRAMES_FOLDER) if f.endswith('.jpg')])\n",
        "\n",
        "    all_frame_data = []\n",
        "\n",
        "    for frame_path in tqdm(frame_files, desc=\"Processing Frames\"):\n",
        "        analysis_result = analyze_frame_colors(frame_path, K_CLUSTERS, RESIZE_WIDTH)\n",
        "        if analysis_result:\n",
        "            analysis_result['frame_path'] = os.path.basename(frame_path)\n",
        "            all_frame_data.append(analysis_result)\n",
        "\n",
        "    # --- 3. aggregate data ---\n",
        "    if all_frame_data:\n",
        "        color_df = pd.DataFrame(all_frame_data)\n",
        "\n",
        "        # save the DataFrame to a CSV file for future analysis\n",
        "        csv_path = os.path.join(DATA_FOLDER, f'{FILM_NAME}_color_analysis.csv')\n",
        "        color_df.to_csv(csv_path, index=False)\n",
        "        print(f\"\\nColor analysis data saved to: {csv_path}\")\n",
        "\n",
        "        # --- 4. generate visualizations ---\n",
        "        plot_color_barcode(color_df, os.path.join(PLOTS_FOLDER, f'{FILM_NAME}_barcode.png'), FILM_NAME)\n",
        "        plot_temporal_graphs(color_df, os.path.join(PLOTS_FOLDER, f'{FILM_NAME}'), FILM_NAME)\n",
        "        plot_overall_palette(color_df, os.path.join(PLOTS_FOLDER, f'{FILM_NAME}_palette.png'), FILM_NAME)\n",
        "        plot_hue_histogram(color_df, os.path.join(PLOTS_FOLDER, f'{FILM_NAME}_hue_hist.png'), FILM_NAME)\n",
        "\n",
        "        print(\"\\n--- Analysis and Visualization Complete! ---\")\n",
        "        print(f\"All outputs can be found in your Google Drive at: {FILM_OUTPUT_PATH}\")\n",
        "    else:\n",
        "        print(\"\\n--- No frames were processed. Halting script. ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxmAKq4iw73v",
        "outputId": "650ef234-a897-451b-d2fe-07c1d7f0edd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Frame Extraction (at 1 FPS) ---\n",
            "Frames extracted successfully.\n",
            "\n",
            "--- Analyzing Frames for Color Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Frames:   0%|          | 0/3100 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "Processing Frames: 100%|█████████▉| 3089/3100 [15:23<00:03,  2.75it/s]/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "Processing Frames: 100%|█████████▉| 3097/3100 [15:24<00:00,  4.35it/s]/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "Processing Frames: 100%|█████████▉| 3098/3100 [15:24<00:00,  4.69it/s]/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "Processing Frames: 100%|██████████| 3100/3100 [15:25<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Color analysis data saved to: /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951/data/royaljourney_1951_color_analysis.csv\n",
            "\n",
            "--- Generating Color Barcode ---\n",
            "Color barcode saved to /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951/plots/royaljourney_1951_barcode.png\n",
            "\n",
            "--- Generating Temporal HSV Plots ---\n",
            "Temporal graphs saved to /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951/plots/royaljourney_1951_hsv_temporal.png\n",
            "\n",
            "--- Generating Overall Film Palette ---\n",
            "Overall palette saved to /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951/plots/royaljourney_1951_palette.png\n",
            "\n",
            "--- Generating Hue Distribution Histogram ---\n",
            "Hue histogram saved to /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951/plots/royaljourney_1951_hue_hist.png\n",
            "\n",
            "--- Analysis and Visualization Complete! ---\n",
            "All outputs can be found in your Google Drive at: /content/drive/MyDrive/MASTERSTHESIS/OUTPUT/royaljourney_1951\n"
          ]
        }
      ]
    }
  ]
}